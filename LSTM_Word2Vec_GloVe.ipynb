{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-Word2Vec-GloVe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Toxic Tweet Classification using LSTM (Long-Short Term Memory) with GloVe & Word2Vec embeddings."
      ],
      "metadata": {
        "id": "Ir0sJFAMcysh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP6abqVlWJCm",
        "outputId": "8fe855b3-e91f-4f88-e66b-5cfeba33d2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required libraries."
      ],
      "metadata": {
        "id": "F23wqmkMdHQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# PyTorch Libraries for implementing LSTM\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Tokenization & word embeddings library\n",
        "from collections import Counter\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "2pSu8W7XWdwe"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing tweets that were pre-processed earlier using various python libraries."
      ],
      "metadata": {
        "id": "JlJhgTY2dVWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/processed-tweets.csv', index_col=0)\n",
        "data = data[data['Basic clean'].notna()]\n",
        "print(\"Number of samples in data = \"+str(len(data)))\n",
        "data.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "KBAmCbZfWVUL",
        "outputId": "3aba322e-1750-48bb-fe28-7375f959943b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in data = 44645\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Basic clean          sentiment  \\\n",
              "0             words katandandre food crapilicious mkr  not_cyberbullying   \n",
              "1   aussietv white mkr theblock today sunrise stud...  not_cyberbullying   \n",
              "2                    classy whore red velvet cupcakes  not_cyberbullying   \n",
              "3   meh p thanks heads concerned another angry dud...  not_cyberbullying   \n",
              "4   isis account pretending kurdish account like i...  not_cyberbullying   \n",
              "5   yes test god good bad indifferent weird whatev...  not_cyberbullying   \n",
              "6   itu sekolah ya bukan tempat bully ga jauh kaya...  not_cyberbullying   \n",
              "7                 karma hope bites kat butt nasty mkr  not_cyberbullying   \n",
              "8                            everything mostly priest  not_cyberbullying   \n",
              "9             rebecca black drops school due bullying  not_cyberbullying   \n",
              "11                                   bully flushes kd  not_cyberbullying   \n",
              "12                                         ughhhh mkr  not_cyberbullying   \n",
              "13  rt turkish state killed 241 children last 11 y...  not_cyberbullying   \n",
              "14  love best response hotcakes managed film nonco...  not_cyberbullying   \n",
              "15  parem de fazer bullying comigo uhahuah bando d...  not_cyberbullying   \n",
              "16           tadinhu de mim sofrendo bulling viu mimi  not_cyberbullying   \n",
              "17         twitter basically angry letters generation  not_cyberbullying   \n",
              "18  best pick line hi cute love people call james ...  not_cyberbullying   \n",
              "19  gotta walk classss officially hate stupid bus ...  not_cyberbullying   \n",
              "20          know saudis chased girls burning building  not_cyberbullying   \n",
              "\n",
              "    tweet_length  \n",
              "0              5  \n",
              "1             10  \n",
              "2              5  \n",
              "3              9  \n",
              "4              8  \n",
              "5             11  \n",
              "6             10  \n",
              "7              7  \n",
              "8              3  \n",
              "9              6  \n",
              "11             3  \n",
              "12             2  \n",
              "13            10  \n",
              "14            10  \n",
              "15             9  \n",
              "16             7  \n",
              "17             5  \n",
              "18            11  \n",
              "19             8  \n",
              "20             6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbf4474e-ecff-4b58-be17-1ca6239d79a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Basic clean</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>words katandandre food crapilicious mkr</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aussietv white mkr theblock today sunrise stud...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>classy whore red velvet cupcakes</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>meh p thanks heads concerned another angry dud...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>isis account pretending kurdish account like i...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>yes test god good bad indifferent weird whatev...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>itu sekolah ya bukan tempat bully ga jauh kaya...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>karma hope bites kat butt nasty mkr</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>everything mostly priest</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>rebecca black drops school due bullying</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>bully flushes kd</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ughhhh mkr</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>rt turkish state killed 241 children last 11 y...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>love best response hotcakes managed film nonco...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>parem de fazer bullying comigo uhahuah bando d...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>tadinhu de mim sofrendo bulling viu mimi</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>twitter basically angry letters generation</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>best pick line hi cute love people call james ...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>gotta walk classss officially hate stupid bus ...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>know saudis chased girls burning building</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbf4474e-ecff-4b58-be17-1ca6239d79a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dbf4474e-ecff-4b58-be17-1ca6239d79a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dbf4474e-ecff-4b58-be17-1ca6239d79a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assigning each class an integer value in the sentiment column and storing the sentiments in an array."
      ],
      "metadata": {
        "id": "aisqFcnfeNiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiments = [\"religion\", \"age\", \"ethnicity\", \"gender\", \"not bullying\", \"other_cyberbullying\"]\n",
        "data['sentiment'] = data['sentiment'].replace({'religion':0, 'age':1, 'ethnicity':2, 'gender':3, 'not_cyberbullying':4, 'other_cyberbullying':5})\n",
        "X = data['Basic clean']\n",
        "Y = data['sentiment']"
      ],
      "metadata": {
        "id": "OtQjqKjQlwSv"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a function to tokenize the column containing texts to a particular length."
      ],
      "metadata": {
        "id": "z1fqVxbG3-yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Tokenize(column, seq_len):\n",
        "    # Creating a vocabulary of words from column\n",
        "    corpus = [word for text in column for word in text.split()]  # List that contains all the words in the tweets\n",
        "    count_words = Counter(corpus)  # Counter object stores the words as dictionary keys and their counts as values\n",
        "    sorted_words = count_words.most_common()  # List which contains tuples and each tuple has (word, count) and they are sorted according to count values\n",
        "    vocab_to_int = {word:i+1 for i, (word,c) in enumerate(sorted_words)}  # Creates a dictionary with keys as words and values as an integer value \n",
        "\n",
        "    # Tokenize the column's text using the vocabulary dictionary created above\n",
        "    text_int = []\n",
        "    for text in column:\n",
        "        r = [vocab_to_int[word] for word in text.split()]\n",
        "        text_int.append(r)\n",
        "    \n",
        "    # Add padding to tokens, each tokenized text is padded so that they have a length = seq_len\n",
        "    text_tokens = np.zeros((len(text_int), seq_len), dtype = int)\n",
        "    for i, token in enumerate(text_int):\n",
        "        if len(token) <= seq_len:\n",
        "            zeros = list(np.zeros(seq_len - len(token)))\n",
        "            new_token = zeros + token\n",
        "        else:\n",
        "            new_token = token[: seq_len]\n",
        "        text_tokens[i, :] = np.array(new_token)\n",
        "\n",
        "    return vocab_to_int, text_tokens"
      ],
      "metadata": {
        "id": "YmKsB7rf3vhm"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = np.max(data['tweet_length'])\n",
        "vocabulary, tokenized_column = Tokenize(data['Basic clean'], max_len)\n",
        "print(\"Total words in vocabulary = \"+str(len(vocabulary)))\n",
        "print(tokenized_column)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2PTgs1g9Gtk",
        "outputId": "64d25b1e-b9da-4506-8345-abb6002db57a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words in vocabulary = 45551\n",
            "[[    0     0     0 ...   612 19727    25]\n",
            " [    0     0     0 ... 11316 19730   221]\n",
            " [    0     0     0 ...   857  9589  6775]\n",
            " ...\n",
            " [    0     0     0 ...   471 45551     3]\n",
            " [    0     0     0 ...    39     4    62]\n",
            " [    0     0     0 ...     8    29   217]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training word2vec embeddings."
      ],
      "metadata": {
        "id": "sMdsHjGW9zW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_train_data = list(map(lambda x : x.split(), data['Basic clean']))\n",
        "embedding_dim = 200\n",
        "word2vec_model = Word2Vec(word2vec_train_data, size=embedding_dim)\n",
        "Vocab_size = len(vocabulary)+1\n",
        "print(\"Size of training data = \"+str(len(word2vec_train_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD_kf_u09odh",
        "outputId": "8aec4424-4292-4702-9d03-daf890258415"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training data = 44645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an embedding matrix that will store embedding of each word in vocabulary. "
      ],
      "metadata": {
        "id": "VaG_viLbKXNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_embedding_matrix = np.zeros((Vocab_size, embedding_dim))  # Defining an embedding matrix for word2vec embeddings\n",
        "for word, token in vocabulary.items():  # Filling the embedding matrix with word2vec trained embeddings\n",
        "  if word2vec_model.wv.__contains__(word):\n",
        "    word2vec_embedding_matrix[token] = word2vec_model.wv.__getitem__(word)\n",
        "\n",
        "print(\"Embedding Matrix Shape = \", word2vec_embedding_matrix.shape)\n",
        "print(word2vec_embedding_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg9EcepY_iWf",
        "outputId": "a0dac18d-d537-4732-894f-3d7b9bf7f7df"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Matrix Shape =  (45552, 200)\n",
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.44084239  0.6012603   0.01929741 ... -0.25910747  0.06569032\n",
            "  -0.06478196]\n",
            " [-0.04002343 -0.31260291  0.04110106 ...  0.14214054 -0.00760728\n",
            "   0.44697773]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing GloVe python library."
      ],
      "metadata": {
        "id": "KN77aHRJIkTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install glove-python-binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU8-VSB0IiRZ",
        "outputId": "7f6627a8-cec0-4992-c4b3-0ab8bca66255"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: glove-python-binary in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training GloVe embeddings."
      ],
      "metadata": {
        "id": "8w75af3OK6IU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_text = []\n",
        "tweet_sentiment = []\n",
        "for key, value in data.iterrows():\n",
        "  tweet = value['Basic clean'].split()\n",
        "  tweet_text.append(tweet)\n",
        "  tweet_sentiment.append(value['sentiment'])"
      ],
      "metadata": {
        "id": "5oDLVI3hIrbI"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glove import Corpus, Glove\n",
        "\n",
        "corpus = Corpus()  # Creating a corpus object that will generate the co-occurence matrix\n",
        "corpus.fit(tweet_text, window = 10)  # Training the corpus to generate the co-occurence matrix that will be used by GloVe\n",
        "glove = Glove(no_components=200, learning_rate=0.05)  # Creating a glove object that will use the matrix created above to create embeddings\n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)  # Training glove to create embeddings\n",
        "glove.add_dictionary(corpus.dictionary)  # Adding corpus dictionary to glove dictionary\n",
        "glove.save('glove.model')  # Saving the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llqQjkJvI1v_",
        "outputId": "c6186c81-332a-4ee4-e881-517d04063dec"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing 30 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an embedding matrix to store glove embeddings."
      ],
      "metadata": {
        "id": "tUsvZtJYLAvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embedding_matrix = np.random.random((len(vocabulary)+1, embedding_dim))\n",
        "count = 0\n",
        "for word, token in vocabulary.items():\n",
        "  embedding_vector = glove.word_vectors[glove.dictionary[word]]\n",
        "  if embedding_vector is not None:\n",
        "    count += 1\n",
        "    glove_embedding_matrix[token] = embedding_vector\n",
        "print(\"Completed!\")\n",
        "print(\"Number of words present in GloVe embeddings = \"+str(count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfIq9jD3JKKb",
        "outputId": "ea75b7bb-dff2-4bf1-da0f-bd2c7770895a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed!\n",
            "Number of words present in GloVe embeddings = 45551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = tokenized_column\n",
        "Y = data['sentiment'].values"
      ],
      "metadata": {
        "id": "Wv0QXZeRLRKq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing stratified train-test split, using 70% for training set, 20% for test set and 10% for validation set."
      ],
      "metadata": {
        "id": "trRgVqHigYNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)  # train-test split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=42)  # train-val split "
      ],
      "metadata": {
        "id": "4BCvbf8ibzBn"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing random oversampling on the training data."
      ],
      "metadata": {
        "id": "Lw5odE99jfUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler()\n",
        "X_train_os, y_train_os = ros.fit_resample(np.array(X_train), np.array(y_train))  # Performing random oversampling"
      ],
      "metadata": {
        "id": "1G3vJPl8cw6B"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After performing oversampling, here we can see that each class has equal number of samples."
      ],
      "metadata": {
        "id": "fWALt6bnlL4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(unique, counts) = np.unique(y_train_os, return_counts=True)\n",
        "np.asarray((unique, counts)).T"
      ],
      "metadata": {
        "id": "-sBgxMnydIq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "137ba4a2-d7d0-4df3-a4d5-3c3860de3811"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0, 5722],\n",
              "       [   1, 5722],\n",
              "       [   2, 5722],\n",
              "       [   3, 5722],\n",
              "       [   4, 5722],\n",
              "       [   5, 5722]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting training data, validation data and test data into tensor data set."
      ],
      "metadata": {
        "id": "umqKbtqLQnWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(torch.from_numpy(X_train_os), torch.from_numpy(y_train_os))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))"
      ],
      "metadata": {
        "id": "Qx9ixUs6hFqC"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using DataLoader so that we can pass the samples in minibatches and shuffle the data at every epoch to reduce model overfitting."
      ],
      "metadata": {
        "id": "9rZPKR-5Tb_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=Batch_size, drop_last=True) \n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=Batch_size, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=Batch_size, drop_last=True)"
      ],
      "metadata": {
        "id": "LN0rP1fLhoCF"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the hyperparameters of the LSTM model."
      ],
      "metadata": {
        "id": "UkLqtZK-UnE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 6  # We are dealing with a multiclass classification problem of 6 classes\n",
        "hidden_dim = 100  # Number of neurons of the internal state (internal neural network in the LSTM)\n",
        "lstm_layers = 1  # Number of stacked LSTM layers\n",
        "LR = 3e-4  # Learning rate\n",
        "dropout = 0.5  # LSTM Dropout\n",
        "bidirectional = True  # Boolean value to choose if to use a bidirectional LSTM or not\n",
        "epochs = 5  # Number of training epochs\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "7evN9m6xmtu_"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a class for our neural network."
      ],
      "metadata": {
        "id": "U3BYZdCRiMKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTM_Sentiment_Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, lstm_layers, bidirectional,batch_size, dropout):\n",
        "        super(BiLSTM_Sentiment_Classifier,self).__init__()\n",
        "        \n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.num_directions = 2 if bidirectional else 1\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            hidden_dim,\n",
        "                            num_layers=lstm_layers,\n",
        "                            dropout=dropout,\n",
        "                            bidirectional=bidirectional,\n",
        "                            batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim*self.num_directions, num_classes)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        self.batch_size = x.size(0)\n",
        "        # EMBEDDING LAYER\n",
        "        embedded = self.embedding(x)\n",
        "        # LSTM LAYERS\n",
        "        out, hidden = self.lstm(embedded, hidden)\n",
        "        # Extract only the hidden state from the last LSTM cell\n",
        "        out = out[:,-1,:]\n",
        "        # FULLY CONNECTED LAYERS\n",
        "        out = self.fc(out)\n",
        "        out = self.softmax(out)\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # Initialization of the LSTM hidden and cell states\n",
        "        h0 = torch.zeros((self.lstm_layers*self.num_directions, batch_size, self.hidden_dim)).detach().to(device)\n",
        "        c0 = torch.zeros((self.lstm_layers*self.num_directions, batch_size, self.hidden_dim)).detach().to(device)\n",
        "        hidden = (h0, c0)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "GUdUMAwUm97j"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiLSTM_Sentiment_Classifier(Vocab_size, embedding_dim, hidden_dim, num_classes, lstm_layers, bidirectional, Batch_size, dropout)  # Creating an object for the model\n",
        "model = model.to(device)\n",
        "model.embedding.weight.data.copy_(torch.from_numpy(glove_embedding_matrix)) # Initialize embedding with the previously defined embedding matrix\n",
        "model.embedding.weight.requires_grad=True # Allowing our embedding matrix to be fined tuned to better adapt to our dataset and get higher accuracy\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7Z7g0mdnNl_",
        "outputId": "0e423b25-8d64-4591-82c3-d07b65403bde"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BiLSTM_Sentiment_Classifier(\n",
            "  (embedding): Embedding(45552, 200)\n",
            "  (lstm): LSTM(200, 100, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=200, out_features=6, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay = 5e-6)"
      ],
      "metadata": {
        "id": "aiZfMcoSnuXR"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)\n",
        "total_step_val = len(valid_loader)\n",
        "\n",
        "early_stopping_patience = 4\n",
        "early_stopping_counter = 0\n",
        "\n",
        "valid_acc_max = 0 # Initialize best accuracy top 0\n",
        "\n",
        "# lists to save the train and validation losses of every batch for each epoch\n",
        "train_loss, valid_loss  = [], []\n",
        "# lists to save the train and validation accuracy of every batch for each epoch\n",
        "train_acc, valid_acc  = [], []\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "    # lists to save the train and validation predictions of every batch for each epoch\n",
        "    y_train_list, y_val_list = [], []\n",
        "\n",
        "    # initalize number of total and correctly classified texts during training and validation\n",
        "    correct, correct_val = 0, 0\n",
        "    total, total_val = 0, 0\n",
        "    running_loss, running_loss_val = 0, 0\n",
        "\n",
        "    model.train() \n",
        "    for inputs, labels in train_loader:  # Training the model\n",
        "        inputs, labels = inputs.to(device), labels.to(device) # load features and targets in device\n",
        "\n",
        "        h = model.init_hidden(labels.size(0))\n",
        "\n",
        "        model.zero_grad() # reset gradients \n",
        "\n",
        "        output, h = model(inputs,h) # get output and hidden states from LSTM network\n",
        "        \n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        y_pred_train = torch.argmax(output, dim=1) # get tensor of predicted values on the training set\n",
        "\n",
        "        y_train_list.extend(y_pred_train.squeeze().tolist()) # transform tensor to list and the values to the list\n",
        "        \n",
        "        correct += torch.sum(y_pred_train==labels).item() # count correctly classified texts per batch\n",
        "        total += labels.size(0) # count total texts per batch\n",
        "\n",
        "    train_loss.append(running_loss / total_step)\n",
        "    train_acc.append(100 * correct / total)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        model.eval()\n",
        "        \n",
        "        for inputs, labels in valid_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            val_h = model.init_hidden(labels.size(0))\n",
        "\n",
        "            output, val_h = model(inputs, val_h)\n",
        "\n",
        "            val_loss = criterion(output, labels)\n",
        "            running_loss_val += val_loss.item()\n",
        "\n",
        "            y_pred_val = torch.argmax(output, dim=1)\n",
        "            y_val_list.extend(y_pred_val.squeeze().tolist())\n",
        "\n",
        "            correct_val += torch.sum(y_pred_val==labels).item()\n",
        "            total_val += labels.size(0)\n",
        "\n",
        "        valid_loss.append(running_loss_val / total_step_val)\n",
        "        valid_acc.append(100 * correct_val / total_val)\n",
        "\n",
        "    # Save model if validation accuracy increases\n",
        "    if np.mean(valid_acc) >= valid_acc_max:\n",
        "        torch.save(model.state_dict(), './state_dict.pt')\n",
        "        print(f'Epoch {e+1}:Validation accuracy increased ({valid_acc_max:.6f} --> {np.mean(valid_acc):.6f}).  Saving model ...')\n",
        "        valid_acc_max = np.mean(valid_acc)\n",
        "        early_stopping_counter=0 # reset counter if validation accuracy increases\n",
        "\n",
        "    else:\n",
        "        print(f'Epoch {e+1}:Validation accuracy did not increase')\n",
        "        early_stopping_counter+=1 # increase counter if validation accuracy does not increase\n",
        "        \n",
        "    if early_stopping_counter > early_stopping_patience:\n",
        "        print('Early stopped at epoch :', e+1)\n",
        "        break\n",
        "    \n",
        "    print(f'\\tTrain_loss : {np.mean(train_loss):.4f} Val_loss : {np.mean(valid_loss):.4f}')\n",
        "    print(f'\\tTrain_acc : {np.mean(train_acc):.3f}% Val_acc : {np.mean(valid_acc):.3f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nhi3vTnRn9SD",
        "outputId": "3f8c4dba-bbe9-4a94-e716-7ab75b938529"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:Validation accuracy increased (0.000000 --> 80.968468).  Saving model ...\n",
            "\tTrain_loss : 0.6511 Val_loss : 0.4513\n",
            "\tTrain_acc : 75.055% Val_acc : 80.968%\n",
            "Epoch 2:Validation accuracy increased (80.968468 --> 82.010135).  Saving model ...\n",
            "\tTrain_loss : 0.5191 Val_loss : 0.4310\n",
            "\tTrain_acc : 80.013% Val_acc : 82.010%\n",
            "Epoch 3:Validation accuracy increased (82.010135 --> 82.423048).  Saving model ...\n",
            "\tTrain_loss : 0.4342 Val_loss : 0.4248\n",
            "\tTrain_acc : 83.511% Val_acc : 82.423%\n",
            "Epoch 4:Validation accuracy increased (82.423048 --> 82.608390).  Saving model ...\n",
            "\tTrain_loss : 0.3700 Val_loss : 0.4352\n",
            "\tTrain_acc : 86.079% Val_acc : 82.608%\n",
            "Epoch 5:Validation accuracy increased (82.608390 --> 82.652027).  Saving model ...\n",
            "\tTrain_loss : 0.3198 Val_loss : 0.4489\n",
            "\tTrain_acc : 88.061% Val_acc : 82.652%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "xpoints = np.array([1, 2, 3, 4, 5])\n",
        "ypoints_train = np.array(train_acc)\n",
        "ypoints_val = np.array(valid_acc)\n",
        "print(ypoints_train)\n",
        "print(ypoints_val)\n",
        "plt.plot(xpoints, ypoints_train, color=\"blue\", label = \"Training\")\n",
        "plt.plot(xpoints, ypoints_val, color=\"orange\", label= \"Validation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FJHfaPukIBAX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "aca8372f-e922-4040-faf2-6f629a714f82"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[75.05538713 84.96968284 90.50839552 93.78206623 95.99172108]\n",
            "[80.96846847 83.0518018  83.24887387 83.16441441 82.82657658]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('./state_dict.pt'))"
      ],
      "metadata": {
        "id": "hhBthnQtpIEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c224b5-bd9d-4784-ba28-7e0770984036"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the models in google drive."
      ],
      "metadata": {
        "id": "eMMeDgiJVjpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_save_name = 'LSTM-word2vec.pt'\n",
        "model_save_name_1 = 'LSTM-GloVe.pt'"
      ],
      "metadata": {
        "id": "iOoenmkoVHFE"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = F\"/content/gdrive/MyDrive/Colab Notebooks/{model_save_name_1}\" "
      ],
      "metadata": {
        "id": "btEPo8XGT2xk"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "z17VbaqDOqss"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq4yQ-CUP6w6",
        "outputId": "5782d8ee-becb-4eaa-8b59-15d7ef380364"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the models on test set."
      ],
      "metadata": {
        "id": "6HZ7bULaWBXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_pred_list = []\n",
        "y_test_list = []\n",
        "for inputs, labels in test_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    test_h = model.init_hidden(labels.size(0))\n",
        "    output, val_h = model(inputs, test_h)\n",
        "    y_pred_test = torch.argmax(output, dim=1)\n",
        "    y_pred_list.extend(y_pred_test.squeeze().tolist())\n",
        "    y_test_list.extend(labels.squeeze().tolist())"
      ],
      "metadata": {
        "id": "kyJcBKMOpLi7"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print('Classification Report for Bi-LSTM :\\n', classification_report(y_test_list, y_pred_list, target_names=sentiments))"
      ],
      "metadata": {
        "id": "xwuQP865pQG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a83f2ae-5b6b-44cb-a1f4-aba067b75c03"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Bi-LSTM :\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "           religion       0.94      0.94      0.94      1590\n",
            "                age       0.96      0.98      0.97      1579\n",
            "          ethnicity       0.97      0.98      0.97      1548\n",
            "             gender       0.81      0.87      0.84      1523\n",
            "       not bullying       0.65      0.54      0.59      1529\n",
            "other_cyberbullying       0.56      0.61      0.58      1159\n",
            "\n",
            "           accuracy                           0.83      8928\n",
            "          macro avg       0.82      0.82      0.82      8928\n",
            "       weighted avg       0.83      0.83      0.83      8928\n",
            "\n"
          ]
        }
      ]
    }
  ]
}